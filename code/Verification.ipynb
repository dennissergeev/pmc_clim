{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Verification of PMCTRACK against ACCACIA and STARS cyclone datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %matplotlib inline\n",
    "import cartopy.crs as ccrs\n",
    "import cf_units\n",
    "from datetime import datetime\n",
    "from IPython.display import clear_output\n",
    "import iris\n",
    "from ipywidgets import interact\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.offsetbox import AnchoredText\n",
    "import matplotlib.colors as mcol\n",
    "from matplotlib.ticker import FuncFormatter\n",
    "import matplotlib.patheffects as PathEffects\n",
    "# import matplotlib.cm as mcm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import random\n",
    "import xarray as xr\n",
    "import string\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "\n",
    "from arke.cart import lcc_map, lcc_map_grid\n",
    "\n",
    "from common_defs import winters, nyr, winter_dates, datasets, cat_kw, aliases, conf_key_typeset, runs_grid_formatter\n",
    "from plot_utils import LCC_KW, trans, clev101, abs_plt_kw, iletters, cc\n",
    "import mypaths\n",
    "from stars_api import read_tracks_file\n",
    "\n",
    "from octant.core import TrackRun, OctantTrack, HOUR\n",
    "from octant.misc import SUBSETS\n",
    "import octant\n",
    "octant.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use('paperfig.mplstyle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lsm = xr.open_dataarray(mypaths.era5_dir / 'lsm.nc').squeeze()\n",
    "lon2d, lat2d = np.meshgrid(lsm.longitude, lsm.latitude)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subsets = SUBSETS[1:]  # only PMC and IC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### All PMCTRACK runs, split into two groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RUNS = dict()\n",
    "RUNS['vort_thresh'] = dict()\n",
    "RUNS['diff_params'] = dict()\n",
    "for dataset in datasets:\n",
    "    _runs = []\n",
    "    for run_id_start in [0, 100]:\n",
    "        with (mypaths.trackresdir / f'{dataset}_{run_id_start:03d}_runs_grid.json').open('r') as f:\n",
    "            for run_id, run_dict in enumerate(json.load(f), run_id_start):\n",
    "                _runs.append( (run_id, run_dict) )\n",
    "\n",
    "    RUNS['vort_thresh'][dataset] = []\n",
    "    RUNS['diff_params'][dataset] = []\n",
    "    for run_id, run_dict in _runs:\n",
    "        if  len(run_dict) == 0 and run_id < 100:\n",
    "            RUNS['diff_params'][dataset].append( (run_id, run_dict) )\n",
    "        if 'zeta_max0' in run_dict or len(run_dict) == 0:\n",
    "            if  run_id >= 100:\n",
    "                if run_dict != {'zeta_max0': 0.0001, 'zeta_min0': 9e-05}:\n",
    "                    RUNS['vort_thresh'][dataset].append( (run_id, run_dict) )\n",
    "        else:\n",
    "            RUNS['diff_params'][dataset].append( (run_id, run_dict) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Verification against ACCACIA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load ACCACIA PMC tracks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accacia_pmcs = pd.read_csv(mypaths.acctracks, delimiter='\\t', names=['N', 'time', 'lon', 'lat'],\n",
    "                           parse_dates=['time'], date_parser=lambda x: datetime.strptime(x, '%Y%m%d%H%M'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_tracks = []\n",
    "for i, df in accacia_pmcs.groupby('N'):\n",
    "    ot = OctantTrack.from_df(df)\n",
    "    if ot.lifetime_h >= 6:\n",
    "        acc_tracks.append(ot)\n",
    "n_ref = len(acc_tracks)\n",
    "n_ref"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_tracks[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load PMCTRACK data for the ACCACIA period"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "period = 'ACCACIA'\n",
    "winter = 'accacia'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRACKS = dict()\n",
    "for run_group, dataset_dicts in tqdm(RUNS.items(), desc='run_group', leave=False):\n",
    "    TRACKS[run_group] = dict()\n",
    "    for dataset, run_dicts in tqdm(dataset_dicts.items(), desc='dataset', leave=False):\n",
    "        TRACKS[run_group][dataset] = []\n",
    "        for run_id, run_dict in tqdm(run_dicts, desc='run_id', leave=False):\n",
    "            track_res_dir = mypaths.trackresdir / dataset / f'run{run_id:03d}' / winter\n",
    "            TR = TrackRun(track_res_dir)\n",
    "            TR.categorise(lsm=lsm, **cat_kw)\n",
    "            TRACKS[run_group][dataset].append(TR)\n",
    "clear_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "method = 'bs2000'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MATCH_RATES = dict()\n",
    "MATCH_PAIRS = dict()\n",
    "for run_group, dataset_dicts in tqdm(RUNS.items(), desc='run_group', leave=False):\n",
    "    results = dict()\n",
    "    MATCH_PAIRS[run_group] = dict()\n",
    "    for dataset, run_dicts in tqdm(dataset_dicts.items(), desc='dataset', leave=False):\n",
    "        MATCH_PAIRS[run_group][dataset] = dict()\n",
    "        perf_table = np.zeros((len(run_dicts), len(subsets)), dtype=np.int64)\n",
    "        for irun, (run_id, run_dict) in tqdm(enumerate(run_dicts), desc='run_id', leave=False):\n",
    "            for isub, subset in tqdm(enumerate(subsets), desc='subsets', leave=False):\n",
    "                match_pairs = TRACKS[run_group][dataset][irun].match_tracks(acc_tracks,\n",
    "                                                                            method=method, beta=50.,\n",
    "                                                                            subset=subset)\n",
    "                if len(run_dict) == 0:\n",
    "                    # save id of matched vortices in the ctrl run ( {} )\n",
    "                    MATCH_PAIRS[run_group][dataset][subset] = match_pairs\n",
    "                perf_table[irun, isub] = len(match_pairs)\n",
    "        if run_group == 'vort_thresh':\n",
    "            index = [r[1].get('zeta_max0', 2e-4) for r in run_dicts]\n",
    "        else:\n",
    "            index = range(len(run_dicts))\n",
    "        results[dataset] = pd.DataFrame(data=perf_table,\n",
    "                                        columns=subsets,\n",
    "                                        index=index)\n",
    "    res_df = pd.merge(*results.values(), how='outer', left_index=True, right_index=True, suffixes=['_'+i for i in datasets])\n",
    "    MATCH_RATES[run_group] = ((res_df / n_ref)\n",
    "                              .reset_index(level=0)\n",
    "                              .rename(columns=dict(index=run_group)))\n",
    "clear_output()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vorticity thresholds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_group = 'vort_thresh'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lcc_kw_zoom = LCC_KW.copy()\n",
    "lcc_kw_zoom.update(extent=[-10, 35, 65, 81],\n",
    "                   ticks=[5, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(18, 9))\n",
    "\n",
    "width = 0.4\n",
    "\n",
    "ax = fig.add_subplot(121)\n",
    "for j, (dataset, color) in enumerate(zip(datasets, cc)):\n",
    "    for i, (subset) in enumerate(subsets):\n",
    "        res_df = MATCH_RATES[run_group]\n",
    "        ax.bar(res_df.index.values + j*width, res_df[f'{subset}_{dataset}'],\n",
    "               width=width,\n",
    "               **color,\n",
    "               alpha= 0.5 * (i+1),\n",
    "               edgecolor='#000000',\n",
    "               linewidth=0.75,\n",
    "               label=f'{dataset}, {aliases[subset]}')\n",
    "        \n",
    "ax.legend(loc=1, ncol=2, fontsize='x-large')\n",
    "\n",
    "for spine in ax.spines.values():\n",
    "    if spine.spine_type in ['top', 'right']:\n",
    "        spine.set_linewidth(0)\n",
    "    else:\n",
    "        spine.set_linewidth(1)\n",
    "\n",
    "ax.set_ylim(0, 1)\n",
    "ax.set_xticks(res_df.index.values + width/2)\n",
    "ax.set_xticklabels((1e4 * res_df[run_group].values).round(decimals=1))\n",
    "\n",
    "percent_formatter = FuncFormatter(lambda x, position: f'{x*100:3.0f}%')\n",
    "ax.yaxis.set_major_formatter(percent_formatter)\n",
    "\n",
    "ax.tick_params(labelsize='large')\n",
    "\n",
    "# Annotate bars\n",
    "fontcolor = '#222222'\n",
    "for i, p in enumerate(sorted(ax.patches, key=lambda x: x.get_x())):\n",
    "    if p.get_height() > 0:\n",
    "        try:\n",
    "            if np.allclose(p.get_x(), _p.get_x()):\n",
    "                fontcolor = '#EEEEEE'\n",
    "                # if abs(p.get_height() - _p.get_height()) < 0.03:\n",
    "                an.set_y(_p.get_height() + 0.005)\n",
    "            else:\n",
    "                fontcolor = '#222222'\n",
    "        except NameError:\n",
    "            pass\n",
    "        \n",
    "        an = ax.annotate('{:d}'.format(int(p.get_height() * n_ref)),\n",
    "                         (p.get_x()+0.2, p.get_height()-0.035),\n",
    "                         ha='center', fontweight='bold', color=fontcolor,\n",
    "                         size='x-large')\n",
    "        _p = p\n",
    "ax.set_xlabel(r'Vorticity threshold used for tracking ($\\times10^{-4}$ $s^{-1}}$)', fontsize='x-large')\n",
    "ax.set_ylabel('Percentage of cyclones detected', fontsize='x-large')\n",
    "# ttl = ax.set_title(f'Number of matched vortices\\nPMCTRACK vs {period}', loc='left', fontsize='xx-large');\n",
    "ax.add_artist(AnchoredText('a', loc=2, prop=dict(size='large')));\n",
    "\n",
    "#\n",
    "# Show on the map what tracks are matched in CTRL runs\n",
    "#\n",
    "ax = lcc_map(fig, 122, **lcc_kw_zoom)\n",
    "\n",
    "run_group = 'vort_thresh'\n",
    "dataset = 'era5'\n",
    "\n",
    "labels = ['Missed',\n",
    "          f'Matched only to {aliases[subsets[0]]}',\n",
    "          f'Matched only to {aliases[subsets[1]]}',\n",
    "          f'Matched to {aliases[subsets[0]]} and {aliases[subsets[1]]}']\n",
    "hs = [None] * 4\n",
    "for idx, acc_df in enumerate(acc_tracks):\n",
    "    acc_df.plot_track(ax=ax, color='C2', linestyle='--', alpha=0.75, **trans)\n",
    "    hs[0], = ax.plot(acc_df.lon[0], acc_df.lat[0], color='C2', linestyle='--', alpha=0.75, **trans)\n",
    "    if idx in [i[1] for i in MATCH_PAIRS[run_group][dataset][subsets[0]]]:\n",
    "        acc_df.plot_track(ax=ax, color='#8DBAD7', linewidth=2, **trans)\n",
    "        hs[1], = ax.plot(acc_df.lon[0], acc_df.lat[0], color='#8DBAD7', linewidth=2, **trans)\n",
    "    if all([idx in [i[1] for i in MATCH_PAIRS[run_group][dataset][subset]] for subset in subsets]):\n",
    "        acc_df.plot_track(ax=ax, color='C0', linewidth=2, **trans)\n",
    "        hs[3], = ax.plot(acc_df.lon[0], acc_df.lat[0], color='C0', linewidth=2, **trans)\n",
    "    elif idx in [i[1] for i in MATCH_PAIRS[run_group][dataset][subsets[1]]]:\n",
    "        acc_df.plot_track(ax=ax, color='#00035b', linewidth=2, **trans)\n",
    "        hs[2], = ax.plot(acc_df.lon[0], acc_df.lat[0], color='#00035b', linewidth=2, **trans)\n",
    "        \n",
    "hs, labels = [h for h, lab in zip(hs, labels) if h], [lab for h, lab in zip(hs, labels) if h]\n",
    "    \n",
    "ax.legend(hs, labels, loc=1, fontsize='x-large')\n",
    "ax.add_artist(AnchoredText('b', loc=2, prop=dict(size='large')));\n",
    "# ax.set_title(f'Number of matched vortices\\nPMCTRACK vs {period}', loc='left', fontsize='xx-large');\n",
    "\n",
    "fig.savefig(mypaths.plotdir / f'vs_{period.lower()}_vort_thresh_w_map_{method}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Other parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_group = 'diff_params'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xlabels = [runs_grid_formatter(run_dict).strip()\n",
    "           for i, (run_id, run_dict) in enumerate(RUNS[run_group]['era5'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(9, 9))\n",
    "\n",
    "width = 0.4\n",
    "\n",
    "ax = fig.add_subplot(111)\n",
    "for j, (dataset, color) in enumerate(zip(datasets, cc)):\n",
    "    for i, (subset) in enumerate(subsets):\n",
    "        res_df = MATCH_RATES[run_group]\n",
    "        ax.bar(res_df.index.values + j*width, res_df[f'{subset}_{dataset}'],\n",
    "               width=width,\n",
    "               **color,\n",
    "               alpha= 0.5 * (i+1),\n",
    "               edgecolor='#000000',\n",
    "               linewidth=0.75,\n",
    "               label=f'{dataset}, {aliases[subset]}')\n",
    "        \n",
    "ax.legend(loc=1, ncol=2, fontsize='x-large')\n",
    "\n",
    "for spine in ax.spines.values():\n",
    "    if spine.spine_type in ['top', 'right']:\n",
    "        spine.set_linewidth(0)\n",
    "    else:\n",
    "        spine.set_linewidth(1)\n",
    "\n",
    "ax.set_ylim(0, 1)\n",
    "ax.set_xticks(res_df.index.values + width/2)\n",
    "ax.set_xticklabels(xlabels, rotation=90)\n",
    "\n",
    "percent_formatter = FuncFormatter(lambda x, position: f'{x*100:3.0f}%')\n",
    "ax.yaxis.set_major_formatter(percent_formatter)\n",
    "\n",
    "ax.tick_params(labelsize='large')\n",
    "\n",
    "# Annotate bars\n",
    "fontcolor = '#222222'\n",
    "for i, p in enumerate(sorted(ax.patches, key=lambda x: x.get_x())):\n",
    "    if p.get_height() > 0:\n",
    "        try:\n",
    "            if np.allclose(p.get_x(), _p.get_x()):\n",
    "                fontcolor = '#EEEEEE'\n",
    "                # if abs(p.get_height() - _p.get_height()) < 0.03:\n",
    "                an.set_y(_p.get_height() + 0.005)\n",
    "            else:\n",
    "                fontcolor = '#222222'\n",
    "        except NameError:\n",
    "            pass\n",
    "        \n",
    "        an = ax.annotate('{:d}'.format(int(p.get_height() * n_ref)),\n",
    "                         (p.get_x()+0.2, p.get_height()-0.035),\n",
    "                         ha='center', fontweight='bold', color=fontcolor,\n",
    "                         size='x-large')\n",
    "        _p = p\n",
    "ax.set_xlabel(r'Tracking parameters', fontsize='x-large')\n",
    "ax.set_ylabel('Percentage of cyclones detected', fontsize='x-large')\n",
    "# ttl = ax.set_title(f'Number of matched vortices\\nPMCTRACK vs {period}', loc='left', fontsize='xx-large');\n",
    "# ax.add_artist(AnchoredText('a', loc=2, prop=dict(size='large')));\n",
    "fig.savefig(mypaths.plotdir / f'vs_{period.lower()}_{run_group}_{method}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Verification against STARS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load STARS tracks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "period = 'stars'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stars = read_tracks_file()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stars_winters = winters[:3]\n",
    "stars_winters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stars_tracks = []\n",
    "for winter in stars_winters:\n",
    "    date_start, date_finish = winter_dates[winter]\n",
    "    for i, df in stars[(stars['time'] >= date_start) & (stars['time'] <= date_finish)].groupby('N'):\n",
    "        ot = OctantTrack.from_df(df)\n",
    "        if ot.lifetime_h >= 6:\n",
    "            stars_tracks.append(ot)\n",
    "n_ref = len(stars_tracks)\n",
    "n_ref"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### All PMCTRACK runs, split into two groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRACKS = dict()\n",
    "for run_group, dataset_dicts in tqdm(RUNS.items(), desc='run_group', leave=False):\n",
    "    TRACKS[run_group] = dict()\n",
    "    for dataset, run_dicts in tqdm(dataset_dicts.items(), desc='dataset', leave=False):\n",
    "        TRACKS[run_group][dataset] = []\n",
    "        for run_id, run_dict in tqdm(run_dicts, desc='run_id', leave=False):\n",
    "            TR = TrackRun()\n",
    "            for winter in tqdm(stars_winters, desc='winter', leave=False):\n",
    "                track_res_dir = mypaths.trackresdir / dataset / f'run{run_id:03d}' / winter\n",
    "                _TR = TrackRun(track_res_dir)\n",
    "                _TR.categorise(lsm=lsm, **cat_kw)\n",
    "                TR += _TR\n",
    "            TRACKS[run_group][dataset].append(TR)\n",
    "clear_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "method = 'simple'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MATCH_RATES = dict()\n",
    "MATCH_PAIRS = dict()\n",
    "for run_group, dataset_dicts in tqdm(RUNS.items(), desc='run_group', leave=False):\n",
    "    results = dict()\n",
    "    MATCH_PAIRS[run_group] = dict()\n",
    "    for dataset, run_dicts in tqdm(dataset_dicts.items(), desc='dataset', leave=False):\n",
    "        MATCH_PAIRS[run_group][dataset] = dict()\n",
    "        perf_table = np.zeros((len(run_dicts), len(subsets)), dtype=np.int64)\n",
    "        for irun, (run_id, run_dict) in tqdm(enumerate(run_dicts), desc='run_id', leave=False):\n",
    "            for isub, subset in tqdm(enumerate(subsets), desc='subsets', leave=False):\n",
    "                match_pairs = TRACKS[run_group][dataset][irun].match_tracks(stars_tracks,\n",
    "                                                                            method=method, beta=50.,\n",
    "                                                                            subset=subset)\n",
    "                if len(run_dict) == 0:\n",
    "                    # save id of matched vortices in the ctrl run ( {} )\n",
    "                    MATCH_PAIRS[run_group][dataset][subset] = match_pairs\n",
    "                perf_table[irun, isub] = len(match_pairs)\n",
    "        if run_group == 'vort_thresh':\n",
    "            index = [r[1].get('zeta_max0', 2e-4) for r in run_dicts]\n",
    "        else:\n",
    "            index = range(len(run_dicts))\n",
    "        results[dataset] = pd.DataFrame(data=perf_table,\n",
    "                                        columns=subsets,\n",
    "                                        index=index)\n",
    "    res_df = pd.merge(*results.values(), how='outer', left_index=True, right_index=True, suffixes=['_'+i for i in datasets])\n",
    "    MATCH_RATES[run_group] = ((res_df / n_ref)\n",
    "                              .reset_index(level=0)\n",
    "                              .rename(columns=dict(index=run_group)))\n",
    "clear_output()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vorticity thresholds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_group = 'vort_thresh'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lcc_kw_zoom = LCC_KW.copy()\n",
    "lcc_kw_zoom.update(extent=[-15, 45, 63, 82],\n",
    "                   ticks=[5, 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(18, 7))\n",
    "\n",
    "width = 0.4\n",
    "\n",
    "ax = fig.add_subplot(121)\n",
    "for j, (dataset, color) in enumerate(zip(datasets, cc)):\n",
    "    for i, (subset) in enumerate(subsets):\n",
    "        res_df = MATCH_RATES[run_group]\n",
    "        ax.bar(res_df.index.values + j*width, res_df[f'{subset}_{dataset}'],\n",
    "               width=width,\n",
    "               **color,\n",
    "               alpha= 0.5 * (i+1),\n",
    "               edgecolor='#000000',\n",
    "               linewidth=0.75,\n",
    "               label=f'{dataset}, {aliases[subset]}')\n",
    "        \n",
    "ax.legend(loc=1, ncol=1, fontsize='x-large')\n",
    "\n",
    "for spine in ax.spines.values():\n",
    "    if spine.spine_type in ['top', 'right']:\n",
    "        spine.set_linewidth(0)\n",
    "    else:\n",
    "        spine.set_linewidth(1)\n",
    "\n",
    "ax.set_ylim(0, 1)\n",
    "ax.set_xticks(res_df.index.values + width/2)\n",
    "ax.set_xticklabels((1e4 * res_df[run_group].values).round(decimals=1))\n",
    "\n",
    "percent_formatter = FuncFormatter(lambda x, position: f'{x*100:3.0f}%')\n",
    "ax.yaxis.set_major_formatter(percent_formatter)\n",
    "\n",
    "ax.tick_params(labelsize='large')\n",
    "\n",
    "# Annotate bars\n",
    "fontcolor = '#222222'\n",
    "for i, p in enumerate(sorted(ax.patches, key=lambda x: x.get_x())):\n",
    "    if p.get_height() > 0:\n",
    "        try:\n",
    "            if np.allclose(p.get_x(), _p.get_x()):\n",
    "                fontcolor = '#EEEEEE'\n",
    "                # if abs(p.get_height() - _p.get_height()) < 0.03:\n",
    "                an.set_y(_p.get_height() + 0.005)\n",
    "            else:\n",
    "                fontcolor = '#222222'\n",
    "        except NameError:\n",
    "            pass\n",
    "        \n",
    "        an = ax.annotate('{:d}'.format(int(p.get_height() * n_ref)),\n",
    "                         (p.get_x()+0.2, p.get_height()-0.035),\n",
    "                         ha='center', fontweight='bold', color=fontcolor,\n",
    "                         size='small')\n",
    "        _p = p\n",
    "ax.set_xlabel(r'Vorticity threshold used for tracking ($\\times10^{-4}$ $s^{-1}}$)', fontsize='x-large')\n",
    "ax.set_ylabel('Percentage of cyclones detected', fontsize='x-large')\n",
    "# ttl = ax.set_title(f'Number of matched vortices\\nPMCTRACK vs {period}', loc='left', fontsize='xx-large');\n",
    "ax.add_artist(AnchoredText('a', loc=2, prop=dict(size='large')));\n",
    "\n",
    "#\n",
    "# Show on the map what tracks are matched in CTRL runs\n",
    "#\n",
    "ax = lcc_map(fig, 122, **lcc_kw_zoom)\n",
    "\n",
    "run_group = 'vort_thresh'\n",
    "dataset = 'era5'\n",
    "\n",
    "labels = ['Missed',\n",
    "          f'Matched only to {aliases[subsets[0]]}',\n",
    "          f'Matched only to {aliases[subsets[1]]}',\n",
    "          f'Matched to {aliases[subsets[0]]} and {aliases[subsets[1]]}']\n",
    "hs = [None] * 4\n",
    "for idx, df in enumerate(stars_tracks):\n",
    "    df.plot_track(ax=ax, color='C2', linestyle='--', alpha=0.75, **trans)\n",
    "    hs[0], = ax.plot(df.lon[0], df.lat[0], color='C2', linestyle='--', alpha=0.75, **trans)\n",
    "    if idx in [i[1] for i in MATCH_PAIRS[run_group][dataset][subsets[0]]]:\n",
    "        df.plot_track(ax=ax, color='#8DBAD7', linewidth=2, **trans)\n",
    "        hs[1], = ax.plot(df.lon[0], df.lat[0], color='#8DBAD7', linewidth=2, **trans)\n",
    "    if all([idx in [i[1] for i in MATCH_PAIRS[run_group][dataset][subset]] for subset in subsets]):\n",
    "        df.plot_track(ax=ax, color='C0', linewidth=2, **trans)\n",
    "        hs[3], = ax.plot(df.lon[0], df.lat[0], color='C0', linewidth=2, **trans)\n",
    "    elif idx in [i[1] for i in MATCH_PAIRS[run_group][dataset][subsets[1]]]:\n",
    "        df.plot_track(ax=ax, color='#00035b', linewidth=2, **trans)\n",
    "        hs[2], = ax.plot(df.lon[0], df.lat[0], color='#00035b', linewidth=2, **trans)\n",
    "        \n",
    "hs, labels = [h for h, lab in zip(hs, labels) if h], [lab for h, lab in zip(hs, labels) if h]\n",
    "    \n",
    "ax.legend(hs, labels, loc=1, fontsize='x-large')\n",
    "ax.add_artist(AnchoredText('b', loc=2, prop=dict(size='large')));\n",
    "# ax.set_title(f'Number of matched vortices\\nPMCTRACK vs {period}', loc='left', fontsize='xx-large');\n",
    "\n",
    "fig.savefig(mypaths.plotdir / f'vs_{period.lower()}_vort_thresh_w_map_{method}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Other parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_group = 'diff_params'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xlabels = [runs_grid_formatter(run_dict).strip()\n",
    "           for i, (run_id, run_dict) in enumerate(RUNS[run_group]['era5'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(9, 9))\n",
    "\n",
    "width = 0.4\n",
    "\n",
    "ax = fig.add_subplot(111)\n",
    "for j, (dataset, color) in enumerate(zip(datasets, cc)):\n",
    "    for i, (subset) in enumerate(subsets):\n",
    "        res_df = MATCH_RATES[run_group]\n",
    "        ax.bar(res_df.index.values + j*width, res_df[f'{subset}_{dataset}'],\n",
    "               width=width,\n",
    "               **color,\n",
    "               alpha= 0.5 * (i+1),\n",
    "               edgecolor='#000000',\n",
    "               linewidth=0.75,\n",
    "               label=f'{dataset}, {aliases[subset]}')\n",
    "        \n",
    "ax.legend(loc=1, ncol=2, fontsize='large') # , bbox_to_anchor=(1, 1.1))\n",
    "\n",
    "for spine in ax.spines.values():\n",
    "    if spine.spine_type in ['top', 'right']:\n",
    "        spine.set_linewidth(0)\n",
    "    else:\n",
    "        spine.set_linewidth(1)\n",
    "\n",
    "ax.set_ylim(0, 1)\n",
    "ax.set_xticks(res_df.index.values + width/2)\n",
    "ax.set_xticklabels(xlabels, rotation=90)\n",
    "\n",
    "percent_formatter = FuncFormatter(lambda x, position: f'{x*100:3.0f}%')\n",
    "ax.yaxis.set_major_formatter(percent_formatter)\n",
    "\n",
    "ax.tick_params(labelsize='large')\n",
    "\n",
    "# Annotate bars\n",
    "fontcolor = '#222222'\n",
    "for i, p in enumerate(sorted(ax.patches, key=lambda x: x.get_x())):\n",
    "    if p.get_height() > 0:\n",
    "        try:\n",
    "            if np.allclose(p.get_x(), _p.get_x()):\n",
    "                fontcolor = '#EEEEEE'\n",
    "                # if abs(p.get_height() - _p.get_height()) < 0.03:\n",
    "                an.set_y(_p.get_height() + 0.005)\n",
    "            else:\n",
    "                fontcolor = '#222222'\n",
    "        except NameError:\n",
    "            pass\n",
    "        \n",
    "        an = ax.annotate('{:d}'.format(int(p.get_height() * n_ref)),\n",
    "                         (p.get_x()+0.2, p.get_height()-0.035),\n",
    "                         ha='center', fontweight='bold', color=fontcolor,\n",
    "                         size='small')\n",
    "        _p = p\n",
    "ax.set_xlabel(r'Tracking parameters', fontsize='x-large')\n",
    "ax.set_ylabel('Percentage of cyclones detected', fontsize='x-large')\n",
    "# ttl = ax.set_title(f'Number of matched vortices\\nPMCTRACK vs {period}', loc='left', fontsize='xx-large');\n",
    "# ax.add_artist(AnchoredText('a', loc=2, prop=dict(size='large')));\n",
    "fig.savefig(mypaths.plotdir / f'vs_{period.lower()}_{run_group}_{method}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:phd]",
   "language": "python",
   "name": "conda-env-phd-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
